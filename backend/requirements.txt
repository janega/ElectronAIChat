
# Core FastAPI
fastapi>=0.95.0
uvicorn[standard]>=0.38.0
python-multipart
httpx>=0.24.0
pydantic>=2.0.0

# Database & ORM
sqlmodel>=0.0.16

# LangChain & Embeddings
langchain>=0.0.300
langchain-community>=0.0.10
langchain-openai>=0.0.3
langchain-ollama
langchain-text-splitters>=0.0.1

# Vector Storage
chromadb>=0.3.28

# Memory System
mem0ai==1.0.1

# Document Processing
PyPDF2>=3.0.0
pypdf>=3.0.0
pdf2image
pytesseract

# LLM Providers
ollama
openai

# Utilities
python-dotenv
numpy
tqdm

# LlamaCpp support
# Install manually with GPU support if needed:
#   CPU:  pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
#   CUDA: pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
llama-cpp-python==0.3.2

# Optional: For downloading models from HuggingFace
huggingface-hub>=0.19.0



